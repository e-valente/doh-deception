{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DoH Deception - Build Models\n",
    "## Author: [Emanuel Valente](https://www.linkedin.com/in/emanuelvalente/) - emanuel.valente@ifood.com.br\n",
    "\n",
    "This notebook builds the main (target) models used in this research. The models are stored as joblib file following the pattern:\n",
    "\n",
    "```shell\n",
    "model_name:\n",
    "<model_algorithm>-<training-dataset>.joblib\n",
    "```"
   ],
   "id": "7f2953da7baefeea"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from joblib import dump"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Loading benign dataset",
   "metadata": {
    "collapsed": false
   },
   "id": "8de823346ba3f4cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset_name = 'e-valente-customized'\n",
    "# Change the following according to the dataset\n",
    "X_features_filename = 'x-e-valente-custom-normalized.csv'\n",
    "y_labels_filename = 'y-evalente-custom-normalized.csv'"
   ],
   "id": "9e1689bd8fad7925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading doh tunnel tool (dnstt) dataset",
   "id": "b04f1122875bee7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Concatenate Tunnel Tool dnstt\n",
    "X = pd.read_csv(X_features_filename, sep=',').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "X = np.array(X)"
   ],
   "id": "ec5e8bb4f59c89cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the Y_features \n",
    "y = pd.read_csv(y_labels_filename, sep=',').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "y = np.array(y)"
   ],
   "id": "d029bedbc85d05db",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Creating Train and Test Data",
   "metadata": {
    "collapsed": false
   },
   "id": "421f08e019bab8a5"
  },
  {
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=3)",
   "metadata": {
    "collapsed": false
   },
   "id": "97f263f25bbbec83",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Defining Model",
   "metadata": {
    "collapsed": false
   },
   "id": "f77388b3c92cb173"
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(models):\n",
    "    model = models\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "        \n",
    "    pred_prob=model.predict_proba(X_test)\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(pred, y_test)\n",
    "    print('Test Accuracy : \\033[32m \\033[01m {:.5f}% \\033[30m \\033[0m'.format(acc*100))\n",
    "    print(classification_report(y_test, pred, digits=4))\n",
    "    cf_matrix = confusion_matrix(y_test, pred)\n",
    "    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True,fmt= '0.2%')\n",
    "    #return acc\n",
    "    return model, acc, fpr, tpr, thresh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bff304fd6128b107",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train model",
   "id": "1be31c9f6e8d2070"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_output_dir = './'",
   "id": "c1fabca5978f461e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gradient Boosting",
   "id": "4f82b8b61ecffa24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_name = 'GradientBoosting'\n",
    "model_1, acc_DTC_1, fpr_1, tpr_1, thresh_1 = build_model(GradientBoostingClassifier(max_depth=12, random_state=0, verbose=True))"
   ],
   "id": "78b091fd424102f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "dump(model_1, '{}/{}-{}.joblib'.format(model_output_dir, model_name, dataset_name))"
   ],
   "id": "3ad9527c53ab6cfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ebdfab24e1e75fc2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
